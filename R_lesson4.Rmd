---
title: "Introduction to R - part 3"
subtitle: "ðŸ§‰"
author: "Tiago Nardi"
institute: "University of Pavia"
output:
  xaringan::moon_reader:
    css: [extra.css, xaringan-themer.css]
    lib_dir: libs
    nature:
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
    includes:
      after_body: insert-logo.html
---


```{r setup, include=FALSE}
options(htmltools.dir.version = FALSE)

```
```{r xaringan-themer, include=FALSE, warning=FALSE}
library(xaringanthemer)
library(gt)
library(DiagrammeR)
  #style_mono_accent(
  style_duo(
  primary_color = "#f2DB86",
  #base_color = "#B2284B",
  secondary_color = "#32577F",

)

# style_duo_accent(primary_color = "#002fa7", secondary_color = "#C5A900")

```
class: inverse, middle, center
# Plot design
---
## Statistical analysis - the basics
Statistical analysis is the science of collecting, exploring and presenting large amounts of data to discover underlying patterns and trends

Statistical analysis can be broken down into five discrete steps, as follows:

1. Describe the nature of the data to be analyzed
2. Explore the relation of the data to the underlying population
3. Create a model to summarize understanding of how the data relates to the underlying
population
4. Prove (or disprove) the validity of the model
5. Employ predective analyses to run scenarios that will help guide future actions

---
## Statistical analysis - the basics
Variable: characteristic detected on each statistical unit, which can take different values in the different statistical units

Observation: value assumed by a variable in a given statistical unit
```{r, include=FALSE}
df_log <- data.frame(Statistical_unit=c("Individual1","Individual2","Individual3"),
                Variable=c("a","b","c")
)
gt_tbl <- gt(df_log)
```

```{r, echo=FALSE}
gt_tbl
```
---
## Variables classification
```{r, eval=TRUE, echo=FALSE}
grViz(diagram = "digraph flowchart {
  node [fontname = arial, shape = box, color=Steelblue]
  tab1 [label = '@@1']
  tab2 [label = '@@2']
  tab3 [label = '@@3']
  tab4 [label = '@@4']
  tab5 [label = '@@5']
  tab6 [label = '@@6']
  tab7 [label = '@@7']
  
  tab1 -> tab2;
  tab1 -> tab3;
  tab2 -> tab4;
  tab2 -> tab5;
  tab3 -> tab6;
  tab3 -> tab7
}
  
  [1]: 'Variables'
  [2]: 'Quantitative Variables'    
  [3]: 'Qualitative variables'
  [4]: 'Discrete'
  [5]: 'Continuous'
  [6]: 'Nominal'
  [7]: 'Ordinal'
  ")
```
---
## Variables classification
### Quantitative variables
  expressed by numbers
- Discrete: can only be particular values within a certain interval (often derived from counts). They are natural numbers
  - Number of colonies per plate
  - Number of chromosomes of a species
- Continuous: can be any value within a given range (they come from measurements). They
are real numbers
  - Weight
  - Height

---
## Variables classification
### Qualitative variables
- #### Nominal: are characterized by different modes that can not be ordered:
  - Sex: male / female
  - Survival: alive / dead
  - Blood groups: A, B, AB, 0
- #### Ordinal: are characterized by different modes that can be ordered:
  - Obesity levels: overweight, obesity I, obesity II, obesity III
  - Intensity of reaction to an antigen: zero, medium, high
  - Educational qualification: compulsory school, bachelor, master, PhD
---
## Analysis flowchart
```{r, eval=TRUE, echo=FALSE}
grViz(diagram = "digraph flowchart {
  node [fontname = arial, shape = box, color=Steelblue]
  tab1 [label = '@@1']
  tab2 [label = '@@2', color=Red]
  tab3 [label = '@@3']
  tab4 [label = '@@4']
  tab5 [label = '@@5']
  tab6 [label = '@@6']
  tab7 [label = '@@7']
  
  tab1 -> tab2;
  tab2 -> tab3;
  tab3 -> tab4;
  tab4 -> tab5;
  tab3 -> tab6;
  tab6 -> tab7
}
  
  [1]: 'Quantitative Variables'
  [2]: 'Check if the variable has a normal distribution'    
  [3]: 'Shapiro-Wilk Normality Test'
  [4]: 'p-value < 0.05'
  [5]: 'Wilcoxon Test'
  [6]: 'p-value >= 0.05'
  [7]: 'Studentâ€™s t Test'
  ")
```
---
## Statistical analysis - the basics

---
## Statistical analysis - the basics
What is a normal distribution?

The normal distribution is a continuous probability distribution that is symmetrical on both sides of the mean, so the right side of the center is a mirror image of the left side

The area under the normal distribution curve represents probability and the total area under the curve sums to one.

Most of the continuous data values in a normal distribution tend to cluster around the
mean, and the further a value is from the mean, the less likely it is to occur
---
## Normal distribution

```{r normal, eval=TRUE, echo = FALSE,, dev.args = list(bg = "transparent")}
normal_distr <- rnorm (n = 50000,
                    mean = 0,
                    sd = 1)
#hist(ab_normal,breaks=100, col="#32577F")
myhist <- hist(normal_distr,breaks=100,col="#32577F")
multiplier <- myhist$counts / myhist$density
mydensity <- density(normal_distr)
mydensity$y <- mydensity$y * multiplier[1]

lines(mydensity,col="red",lwd = 4)

```
---
## Testing the normality
.pull-left[
To the test the normality we use the Shapiro-Wilk test

```{r, eval=FALSE}
shapiro.test(numeric_vector)
```
- The null hypothesis for this test is that the data are normally distributed

- The alternative hypothesis for this test is that the data are not normally distributed
]
.pull-right[![](img/abby.gif)]
---
class: middle
## Testing the normality
- If the __p-value__ is less than __0.05__ (5%), we rejected the null hypothesis and we assume the variable does not have a __normal distribution__

- If the __p-value__ is more than  __0.05__ (5%), we assume the null hypothesis is true   and we assume that the variable has a __normal distribution__

---
class: inverse, middle
## Important Reminder
.pull-left[
### The p-value is the probability of obtaining test results at least as extreme as the results actually observed, under the assumption that the null hypothesis is correct]
.pull-right[![](img/cards.gif)]
---
class: inverse, middle, center
## Other Reminder
### The 0.05 (1/20) is a commonly used threshold, often considered adeguate. It's used a standard value, but there is no inherent reasons to prefer this specific value

---
class: inverse, middle, center, hide-logo
## In RA Fisher own words
.pull-left[
#### "If one in twenty does not seem high enough odds, we may, if we prefer it, draw the line at one in fifty or one in a hundred. Personally, the writer prefers to set a low standard of significance at the 5 per cent point, and ignore entirely all results which fails to reach this level. A scientific fact should be regarded as experimentally established only if a properly designed experiment rarely fails to give this level of significance"
Fisher, R. A. 1926. The arrangement of field experiments. Journal of the
Ministry of Agriculture. 33, pp. 503-515]

.pull-right[![](img/fisher.jpg)]
---
## Have a try
Load the usual tableand see if the *Contigs* variable has a normal distribution 
```{r eval=FALSE}
db <- read.csv("patric_redux.csv")
shapiro.test(vector_name)
```
---
## Statistical analysis - the basics
Example:
S.aures vs M.tuberculosis: is the genome size significantly different between the two species?
df <- read.table("PATRIC_Statistics.csv",header = T,stringsAsFactors = F)
str(df)
table(df$Bacterium)
tuberculosis <- subset(stat,Bacterium=="M_tuberculosis")
tuberculosis<-droplevels(tuberculosis)
aureus <- subset(stat,Bacterium=="S_aureus")
aureus<-droplevels(aureus)
g_tuberculosis <- tuberculosis$Genome.Length
# quantitative variable
g_aureus <- aureus$Genome.Length
# quantitative variable
shapiro.test(g_aureus) #the variable DOES NOT have a Normal distribution
shapiro.test(g_tuberculosis) #the variable DOES NOT have a Normal distribution
wilcox.test(g_aureus,g_tuberculosis) #p-value < 2.2e-16
Genome size mean value is significantly different between the two species
---
## Statistical analysis - the basics
```{r, eval=TRUE, echo=FALSE}
grViz(diagram = "digraph flowchart {
  node [fontname = arial, shape = box, color=Steelblue]
  tab1 [label = '@@1']
  tab2 [label = '@@2']
  tab3 [label = '@@3',color=red]
  tab4 [label = '@@4',color=red]

  tab1 -> tab2;
  tab2 -> tab3;
  tab2 -> tab4
}
  
  [1]: 'Qualitative Variables'
  [2]: 'Chi-Square Test'    
  [3]: 'p-value < 0.05'
  [4]: 'p-value >= 0.05'
  ")
```

---
How to test whether there is an association between categorical variables:
Qualitative variable
Chi-square Test
p-value < 0.05
p-value >= 0.05Statistical analysis - the basics
Chi-square test: it determines whether there is an association between categorical variables (i.e.,
whether the variables are independent or related). This test utilizes a contingency table to analyze the
data. A contingency table (or two-way table) is an arrangement in which data is classified according
to two categorical variables. The categories for one variable appear in the rows, and the categories for
the other variable appear in columns. Each variable must have two or more categories. Each cell
reflects the total count of cases for a specific pair of categories
â€¢ The null hypothesis for this test is that the categorical variables are indipendent (no correlation)
â€¢ The alternative hypothesis for this test is that the categorical variables are correlated
For this test, the p-value is the probability that the null hypothesis is true. If the p-value is less
than 0.05, then the null hypothesis is rejected (because the probability is < 5%)Statistical analysis - the basics
How to create a contingency table:
contingency_table <- table(dataframe_name$column_1, dataframe_name$column_2)
chisq.test(contingency_table)
p-value calculated < 0.05The variables are dependent and related
p-value calculated >= 0.05The variables are independentStatistical analysis - the basics
Example:
S.aures vs M.tuberculosis: is there a correlation between the microorganism and the outcome?
t <- table(df$Bacterium,df$Outcome)
chisq.test(t)
The test is significant (p-vale < 0.05). The outcome is correlated with the microorganism

---
# Histograms
.pull-left[
Histogram plot with default values
```{r }
db <- read.csv("patric_redux.csv")

```
]
